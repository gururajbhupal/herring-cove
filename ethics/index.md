

<h1> Ethics Assignment </h1>
##### Jackson Kopitz, Rami Pellumbi, Jonathan Cruz, Gururaj Bhupal  
<br>
<br>
#### Is “a ban on offensive autonomous weapons beyond meaningful human control” going to work?


<img src="{{ site.baseurl }}/images/ethic_1.png" alt="Ethics1" class="center">

<br>
<br>
To answer this, one of our team members drew a cartoon which compares the potential future with autonomous weapons to the present. The two different scenarios show how scary the future could be if weapons are “given” intelligence.  
The realm of Robotics and Automation was introduced to ease the work of humans across all disciplines. Autonomous systems in all fields ease repetitive and tiring work that a human would otherwise have to do.  
<br>
Focusing our view on autonomous weapons, we think that a ban on offensive autonomous weapons beyond meaningful human control would work if defined by a well-defined set of global laws. However, whether it would be worth it or not is another discussion.  
<br>
**Pro**  
If you are a country using Autonomous Weapons, then you will face lesser human loss in warfare since you eliminate the need for humans on the battlefield.  
<br>
**Cons**  
Once one country develops autonomous warfare, the poorer countries are “doomed”. It creates a hierarchy structure which won’t be feasible. We would either need to regulate “battlefield rules” or ban the use of the technology we just created.  
<br>
Further evaluation leads us to believe that this system will not inhibit any development and research in IPS since regulations are only applied on defense systems. Intelligent Physical Systems are used and will be used in every field in the industry.
In conclusion, we believe that *“a ban on offensive autonomous weapons beyond meaningful human control”* is necessary. We end the discussion with another cartoon. Hail robotics!


<img src="{{ site.baseurl }}/images/ethic_2.png" alt="Ethics2" class="center">
